# Code-Switched Text Analysis Pipeline

This project analyzes the impact of code-switching on text toxicity using the Perspective API and various language models.

## Pipeline Overview

The main workflow involves several steps managed by Slurm job scripts:

1.  **Initial Filtering (Manual/Previous Step):** Input data is filtered (e.g., `new_outputs/filtered_output.csv`).
2.  **Initial Perspective Scores (`05_...` Script - Step 1):** Runs Perspective API on the *code-switched prompts* from the filtered input (`generated` column) -> `new_outputs/perspective/code_switched_perspective.csv`.
3.  **Local Continuation Generation (`05_...` Script - Step 2):**
    *   Uses `new_python_scripts/generate_continuations_local.py`.
    *   Takes the output from the previous step as input.
    *   Generates continuations locally for Llama 3, Llama 3.1, and Aya based on the `generated` column (code-switched prompts).
    *   Saves results to `new_outputs/llama_local/` (e.g., `code_switched_llama3.csv`).
4.  **Perspective Scores on CS Continuations (`05_...` Script - Step 3):**
    *   Uses `new_python_scripts/run_perspective_api.py`.
    *   Runs Perspective API on the *code-switched continuations* generated in the previous step.
    *   Saves results to `new_outputs/perspective/` (e.g., `llama3_continuations_perspective_local.csv`).
5.  **Local Generation for Src/Tgt (`07_...` Script):**
    *   Uses `new_python_scripts/generate_continuations_local.py`.
    *   Generates continuations locally for Llama 3, Llama 3.1, and Aya based on the *original `src` (English)* and *`tgt` (Hindi)* columns from `code_switched_perspective.csv`.
    *   Saves results to `new_outputs/src_results/` and `new_outputs/tgt_results/`.
6.  **Comparison of Scores (`08_...` Script):**
    *   Uses `new_python_scripts/compare_src_tgt_cs.py`.
    *   Runs Perspective API on the `src` and `tgt` continuations generated in the previous step.
    *   Loads the existing scores for the `cs` continuations.
    *   Performs statistical tests (t-test, Wilcoxon) and generates summary statistics and box plots comparing scores (Toxicity, Identity Attack, Insult) across the three conditions (Src Continuations, Tgt Continuations, CS Continuations) for each model.
    *   Saves the combined scores needed for heatmaps.
    *   Calls `new_python_scripts/generate_heatmaps.py` to create correlation heatmaps (En vs CS, Hi vs CS).
    *   Saves all comparison results to `new_outputs/comparison_src_tgt_cs_results/`.

## Interpreting the Comparison Results

Detailed analysis and interpretation of the output files generated by the comparison script (`08_compare_src_tgt_cs.sh`) can be found in [ANALYSIS.md](ANALYSIS.md). This includes explanations of the summary statistics, statistical tests, box plots, and heatmaps.

## File Structure

*   `new_python_scripts/`: Contains the Python scripts.
    *   `generate_continuations_local.py`: Generates continuations locally.
    *   `run_perspective_api.py`: Runs Perspective API on a column.
    *   `compare_src_tgt_cs.py`: Runs Perspective API on src/tgt, compares scores.
    *   `generate_heatmaps.py`: Creates correlation heatmaps.
*   `new_job_scripts/`: Contains Slurm job scripts.
    *   `05_generate_continuations_local.sh`: Runs steps 1-4 (Initial Perspective, Local CS Generation, Perspective on CS Continuations).
    *   `07_generate_src_tgt_local.sh`: Runs step 5 (Local Src/Tgt Generation).
    *   `08_compare_src_tgt_cs.sh`: Runs step 6 (Comparison analysis, including API calls for src/tgt, stats, plots, heatmaps).
*   `en_hi_results_vera/`: Contains original English/Hindi data (`.pkl`).
*   `new_outputs/`: Contains generated results.
    *   `perspective/`: Perspective scores.
    *   `llama_local/`: Locally generated CS continuations.
    *   `src_results/`: Locally generated Src continuations.
    *   `tgt_results/`: Locally generated Tgt continuations.
    *   `comparison_src_tgt_cs_results/`: Final comparison tables, plots, and heatmaps.
*   `job_outputs/`: Slurm job output files.
*   `config.py`: Contains API keys.

## How to Run Full Pipeline

1.  Ensure `config.py` has `PERSPECTIVE_API_KEY` and `HUGGINGFACE_API_KEY`.
2.  Ensure `new_outputs/filtered_output.csv` exists.
3.  Run `sbatch new_job_scripts/05_generate_continuations_local.sh` (wait for completion).
4.  Run `sbatch new_job_scripts/07_generate_src_tgt_local.sh` (wait for completion).
5.  Run `sbatch new_job_scripts/08_compare_src_tgt_cs.sh`.
6.  Check results in `new_outputs/comparison_src_tgt_cs_results/`. 